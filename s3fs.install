<?php

/**
 * @file
 * Install, update and uninstall functions for the S3 File System module.
 */

/**
 * Implements hook_requirements().
 */
function s3fs_requirements($phase) {
  $t = get_t();

  if ($phase != 'runtime') {
    return array();
  }

  $fopen_allowed = ini_get('allow_url_fopen');
  $ok_message = $t('The PHP allow_url_fopen setting is on.');
  $error_message = $t('The S3 File System module requires that the allow_url_fopen setting be turned on in php.ini.');

  $requirements['s3fs_allow_url_fopen'] = array(
    'severity' => $fopen_allowed ? REQUIREMENT_OK : REQUIREMENT_ERROR,
    'title' => 'S3 File System',
    'value' => 'allow_url_fopen',
    'description' => $fopen_allowed ? $ok_message : $error_message,
  );

  if ($phase == 'runtime') {
    $int64_ok = (PHP_INT_MAX === 9223372036854775807);
    $requirements['s3fs_int64'] = array(
      'title' => t('Support caching S3 file data for files larger than 2GB'),
      'value' => $int64_ok ? t('Available') : t('Unavailable'),
      'description' => t('A 64-bit PHP installation is required in order to support files larger than 2GB.'),
      'severity' => $int64_ok ? REQUIREMENT_OK : REQUIREMENT_WARNING,
    );
  }

  // TODO: Add check for awssdk library.
  return $requirements;
}

/**
 * Implements hook_uninstall().
 */
function s3fs_uninstall() {
  variable_del('s3fs_bucket');
  variable_del('s3fs_cname');
  variable_del('s3fs_domain');
  variable_del('s3fs_customhost');
  variable_del('s3fs_hostname');
  variable_del('s3fs_torrents');
  variable_del('s3fs_presigned_urls');
  variable_del('s3fs_saveas');
  variable_del('s3fs_ignore_cache');
}

/**
 * Implements hook_schema().
 */
function s3fs_schema() {
  $schema['s3fs_file'] = array(
    'description' => 'Stores metadata about files in the S3 File System.',
    'fields' => array(
      'uri' => array(
        'description' => 'The S3 URI of the file.',
        'type' => 'varchar',
        'length' => 255,
        'not null' => TRUE,
        'default' => '',
      ),
      'filesize' => array(
        'description' => 'The size of the file in bytes.',
        'type' => 'int',
        'size' => 'big',
        'unsigned' => TRUE,
        'not null' => TRUE,
        'default' => 0,
      ),
      'timestamp' => array(
        'description' => 'UNIX timestamp for when the file was added.',
        'type' => 'int',
        'unsigned' => TRUE,
        'not null' => TRUE,
        'default' => 0,
      ),
      'dir' => array(
        'description' => 'Boolean indicating whether or not this object is a directory.',
        'type' => 'int',
        'not null' => TRUE,
        'default' => 0,
      ),
      'mode' => array(
        'description' => 'The file mode returned by the stat function.',
        'type' => 'int',
        'unsigned' => TRUE,
        'not null' => TRUE,
        'default' => 0,
      ),
      'uid' => array(
        'description' => 'The S3 uid of the user who is associated with the file.',
        'type' => 'varchar',
        'length' => 255,
        'not null' => TRUE,
        'default' => '',
      ),
    ),
    'indexes' => array(
      'timestamp' => array('timestamp'),
    ),
    'primary key' => array('uri'),
    'collation' => 'utf8_bin',
  );

  return $schema;
}

/**
 * Allow large filesize values in the S3 File Metadata cache.
 */
function s3fs_update_7000() {
  $spec = array(
    'description' => 'The size of the file in bytes.',
    'size' => 'big',
    'type' => 'int',
    'unsigned' => TRUE,
    'not null' => TRUE,
    'default' => 0,
  );
  db_change_field('s3fs_file', 'filesize', 'filesize', $spec);
  
  $bucket = variable_get('s3fs_bucket', FALSE);
  if ($bucket) {
    _s3fs_refresh_cache($bucket);
  }
  else {
    drupal_set_message(t('S3 bucket name unknown. Unable to refresh metadata cache table.'), 'error');
  }
}
