<?php

/**
 * @file
 * Sets up the s3fsStreamWrapper class to be used as a Drupal file system.
 */

/**
 * The version number of the current release.
 */
define('S3FS_VERSION', '7.x-0.2-dev');

/**
 * Class used to differentiate between known and unknown exception states.
 */
class s3fsException extends Exception {}

/**
 * Implements hook_stream_wrappers().
 */
function s3fs_stream_wrappers() {
  return array(
    's3' => array(
      'name' => 'S3 File System',
      'class' => 's3fsStreamWrapper',
      'description' => t('Amazon Simple Storage Service'),
    ),
  );
}

/**
 * Implements hook_libraries_info()
 */
function s3fs_libraries_info() {
  return array(
    'awssdk2' => array(
      'title' => 'AWS SDK for PHP 2',
      'vendor url' => 'http://docs.aws.amazon.com/aws-sdk-php/guide/latest/index.html',
      'download url' => 'https://github.com/aws/aws-sdk-php/releases/download/2.4.10/aws.zip',
      'version arguments' => array(
        'file' => 'Aws/Common/Aws.php',
        'pattern' => "/const VERSION = '(.*)';/",
        'lines' => 200,
      ),
      'files' => array(
        'php' => array(
          'aws-autoloader.php',
        ),
      ),
    ),
  );
}

/**
 * Implements hook_menu().
 */
function s3fs_menu() {
  $items = array();
  
  $items['admin/config/media/s3fs/settings'] = array(
    'title' => 'S3 File System Settings',
    'description' => 'Configure S3 File System settings.',
    'page callback' => 'drupal_get_form',
    'page arguments' => array('s3fs_settings'),
    'access arguments' => array('administer s3fs'),
    'file' => 's3fs.admin.inc',
  );
  $items['admin/config/media/s3fs/actions'] = array(
    'title' => 'S3 File System Actions',
    'description' => 'Actions for S3 File System.',
    'page callback' => 'drupal_get_form',
    'page arguments' => array('s3fs_actions'),
    'access arguments' => array('administer s3fs'),
    'file' => 's3fs.admin.inc',
  );
  // A custom version of system/files/styles/%image_style, based on how the
  // core Image module creates image styles with image_style_deliver().
  $items['s3/files/styles/%image_style'] = array(
    'title' => 'Generate image style in S3',
    'page callback' => '_s3fs_image_style_deliver',
    'page arguments' => array(3),
    'access callback' => TRUE,
    'type' => MENU_CALLBACK,
  );
  
  return $items;
}

/**
 * Implements hook_permission().
 */
function s3fs_permission() {
  return array(
    'administer s3fs' => array(
      'title' => t('Administer S3 File System'),
    ),
  );
}

/**
 * Implements hook_help().
 */
function s3fs_help($path, $arg) {
  $actions = 'admin/config/media/s3fs/actions';
  $settings = 'admin/config/media/s3fs/settings';
  if ($path == $settings) {
    $msg = t("To configure your Amazon Web Services credentials, set \$conf['awssdk2_access_key'] and \$conf['awssdk2_secret_key'] in your site's settings.php file.");
    $msg .= '<br>' . t('To perform actions, visit the !link', array('!link' => l(t('actions page'), $actions)));
    return "<p>$msg</p>";
  }
  elseif ($path == $actions) {
    $msg = t('These are the actions that you can perform upon S3 File System.');
    $msg .= '<br>' . t('To change your settings, visit the !link.', array('!link' => l(t('settings page'), $settings)));
    return "<p>$msg</p>";
  }
}

/**
 * Generates an image derivative in S3.
 *
 * This is a re-write of the core Image module's image_style_deliver() function.
 * It exists to improve the performance of serving newly-created image
 * derivatives from S3.
 *
 * Note to future maintainers: this function is variatic. It accepts two fixed
 * arguments: $style and $scheme, and any number of further arguments, which
 * represent the path to the file in S3 (split on the slahses).
 */
function _s3fs_image_style_deliver() {
  // Drupal's black magic calls this function with the image style as arg0,
  // the scheme as arg1, and the full path to the filename split across arg2+.
  // So we need to use PHP's version of variatic functions to get the complete
  // filename.
  $args = func_get_args();
  $style = array_shift($args);
  // The second parameter ($scheme) is unused, since we know we're using s3://.
  array_shift($args);
  $filename = implode('/', $args);
  
  $valid = !empty($style);
  if (!variable_get('image_allow_insecure_derivatives', FALSE) || strpos(ltrim($filename, '\/'), 'styles/') === 0) {
    $valid = $valid && isset($_GET[IMAGE_DERIVATIVE_TOKEN]) && $_GET[IMAGE_DERIVATIVE_TOKEN] === image_style_path_token($style['name'], "s3://$filename");
  }
  if (!$valid) {
    return MENU_ACCESS_DENIED;
  }
  
  $image_uri = "s3://$filename";
  $derivative_uri = image_style_path($style['name'], $image_uri);
  
  // Copy the image from S3 into a local temporary file.
  $data = file_get_contents($image_uri);
  $temp_name = drupal_tempnam('temporary://', 's3image');
  if (file_put_contents($temp_name, $data) === FALSE) {
    drupal_set_message(t('The file could not be created.'), 'error');
    watchdog('S3 File System', 'Unable to store original image %path to a temporary location for image style generation.', array('%path' => $image_uri));
    drupal_add_http_header('Status', '500 Internal Server Error');
    print t('Error generating image.');
    drupal_exit();
  }
  
  // Don't start generating the image if the derivative already exists or if
  // generation is in progress in another thread.
  $lock_name = '_s3fs_image_style_deliver:' . $style['name'] . ':' . drupal_hash_base64($image_uri);
  if (!file_exists($derivative_uri)) {
    $lock_acquired = lock_acquire($lock_name);
    if (!$lock_acquired) {
      // Tell client to retry again in 3 seconds. No browsers are currently
      // known to support Retry-After, though.
      drupal_add_http_header('Status', '503 Service Unavailable');
      drupal_add_http_header('Retry-After', 3);
      print t('Image generation in progress. Try again shortly.');
      drupal_exit();
    }
  }
  
  // Try to generate the image, unless another thread just did it while we were
  // acquiring the lock and setting up.
  $success = file_exists($derivative_uri) || image_style_create_derivative($style, $temp_name, $derivative_uri);
  drupal_unlink($temp_name);
  
  if (!empty($lock_acquired)) {
    lock_release($lock_name);
  }
  
  if ($success) {
    // Perform a 302 Redirect to the newly-created iamge derivative.
    drupal_goto(file_create_url($derivative_uri));
  }
  else {
    watchdog('S3 File System', 'Unable to generate the derived image located at %path.', array('%path' => $derivative_uri));
    drupal_add_http_header('Status', '500 Internal Server Error');
    print t('Error generating image.');
    drupal_exit();
  }
}

/**
 * Checks all the configuration options to ensure that they're valid.
 *
 * @return bool
 *   TRUE if config is good to go, otherwise FALSE.
 */
function _s3fs_validate_config($config) {
  if (!empty($config['use_customhost']) && empty($config['hostname'])) {
    form_set_error('s3fs_hostname', 'You must specify a hostname to use the Custom Hostname feature.');
    return FALSE;
  }
  
  try {
    $s3 = _s3fs_get_amazons3_client($config);
  }
  catch (s3fsException $e) {
    form_set_error('s3fs_bucket', $e->getMessage());
    return FALSE;
  }
  
  try {
    // Test the connection to S3.
    $use_instance_profile = variable_get('aws_use_instance_profile', FALSE);
    // TODO: http://docs.aws.amazon.com/AmazonS3/latest/dev/AuthUsingTempSessionTokenPHP.html
    //   Tells how to use IAM Roles/Instance Profile (I think?)
    
    // Call listBuckets() to trigger any exceptions which might occur due to
    // invalid configuration. doesBucketExist() doesn't work for that.
    $buckets = $s3->listBuckets();
    
    if (!$s3->doesBucketExist($config['bucket'])) {
      form_set_error('s3fs_bucket', t('The bucket %bucket does not exist in the %region region.',
        array('%bucket' => $config['bucket'], '%region' => $config['region'] ? $config['region'] : 'default')));
      return FALSE;
    }
  }
  catch (Aws\S3\Exception\InvalidAccessKeyIdException $e) {
    form_set_error('', t('The Access Key in your AWS credentials is invalid.'));
    return FALSE;
  }
  catch (Aws\S3\Exception\SignatureDoesNotMatchException $e) {
    form_set_error('', t('The Secret Key in your AWS credentials is invalid.'));
    return FALSE;
  }
  catch (Exception $e) {
    form_set_error('s3fs_bucket', t('An unexpected %exception occured, with the following error message:<br>%error',
      array('%exception' => get_class($e), '%error' => $e->getMessage())));
    return FALSE;
  }
  
  return TRUE;
}

/**
 * Refreshes the metadata cache.
 *
 * Iterates over the full list of objects in the S3 bucket, storing their
 * metadata in the cache. Then creates the ancestor folders for those files.
 *
 * @param array $config
 *   An s3fs configuration array.
 */
function _s3fs_refresh_cache($config) {
  // Bomb out with an error if our configuration settings are invalid.
  if (!_s3fs_validate_config($config)) {
    form_set_error('s3fs_refresh_cache][refresh', t('Unable to validate S3 configuration settings.'));
    return;
  }
  $s3 = _s3fs_get_amazons3_client($config);
  
  // Clear the files out of the metadata table, so we can recreate them from
  // scratch. Directories are not erased because empty directories could not
  // be regenerated.
  db_delete('s3fs_file')
    ->condition('dir', 0, '=')
    ->execute();
  
  // Set up the iterator that will loop over all the objects in the bucket.
  $page_size = 1000;
  $file_metadata_list = array();
  $iterator = $s3->getListObjectsIterator(array('Bucket' => $config['bucket']));
  $iterator->setPageSize($page_size);
  
  // The $folders array is an associative array keyed by folder names, which
  // is constructed as each filename is written to the DB. After all the files
  // are written, the folder names are converted to metadata and written.
  $folders = array();
  
  // Set up an event listener to consume each page of results before the next
  // request is made.
  $dispatcher = $iterator->getEventDispatcher();
  $dispatcher->addListener('resource_iterator.before_send', function($event) use ($iterator, &$file_metadata_list, &$folders) {
    _s3fs_write_metadata($file_metadata_list, $folders);
  });
  
  foreach ($iterator as $s3_metadata) {
    $uri = "s3://{$s3_metadata['Key']}";
    
    if ($uri[strlen($uri) - 1] == '/') {
      // Treat objects in S3 whose filenames end in a '/' as folders.
      $uri = rtrim($uri, '/');
      $folders[$uri] = $uri;
    }
    else {
      // Treat the rest of the files normally.
      $file_metadata_list[] = _s3fs_convert_metadata($uri, $s3_metadata);
    }
  }
  // Push the last page of metadata to the DB. The event listender doesn't do
  // this for us because it doesn't fire after the last page is done.
  _s3fs_write_metadata($file_metadata_list, $folders);
  
  // Now that the $folders array contains all the ancestors of every file in
  // the cache, write those folders to the DB.
  if ($folders) {
    // SELECT all the folders that are already in the DB and remove them from
    // $folders, so we can safely do an INSERT. Using db_merge() is too slow,
    // because it doesn't support multiple rows in a single query.
    $existing_folders = db_select('s3fs_file', 's')
      ->fields('s', array('uri'))
      ->condition('dir', 1, '=')
      ->execute()
      ->fetchCol(0);
    foreach ($existing_folders as $existing) {
      unset($folders[$existing]);
    }
    
    // Once we've pruned the existing folders, there may be none left.
    if ($folders) {
      $insert_query = db_insert('s3fs_file')
        ->fields(array('uri', 'filesize', 'timestamp', 'dir', 'mode', 'uid'));
      foreach ($folders as $folder_uri) {
        $metadata = _s3fs_convert_metadata($folder_uri, array());
        $insert_query->values($metadata);
      }
      $insert_query->execute();
    }
  }
  
  drupal_set_message(t('S3 File System cache refreshed.'));
}

/**
 * Helper function to write metadata to the DB.
 *
 * @param array $file_metadata_list
 *   An array passed by reference, which contains the current page of file
 *   metadata. This function empties out $file_metadata_list at the end.
 * @param array $folders
 *   An associative array keyed by folder name, which is populated with the
 *   ancestor folders for each file in $file_metadata_list.
 */
function _s3fs_write_metadata(&$file_metadata_list, &$folders) {
  if ($file_metadata_list) {
    $insert_query = db_insert('s3fs_file')
      ->fields(array('uri', 'filesize', 'timestamp', 'dir', 'mode', 'uid'));
    foreach ($file_metadata_list as $metadata) {
      // Write the file metadata to the DB.
      $insert_query->values($metadata);
      
      // Add the ancestor folders of this file to the $folders array.
      $uri = dirname($metadata['uri']);
      while (strlen($uri) > 5) {
        // Loop until the URI is shorter than 's3://x'
        $folders[$uri] = $uri;
        $uri = dirname($uri);
      }
    }
    $insert_query->execute();
  }
  
  // Empty out the file array, so it can be re-filled by the next request.
  $file_metadata_list = array();
}

/**
 * Convert file metadata returned from S3 into a metadata cache array.
 *
 * @param string $uri
 *   A string containing the uri of the resource to check.
 * @param array $s3_metadata
 *   An array containing the collective metadata for the Amazon S3 object.
 *   The caller may send an empty array here to indicate that the returned
 *   metadata should represent a directory.
 *
 * @return array
 *   An array containing metadata formatted for the file metadata cache.
 */
function _s3fs_convert_metadata($uri, $s3_metadata) {
  $metadata = array('uri' => $uri);
  
  if (empty($s3_metadata)) {
    // The caller wants directory metadata, so invent some.
    $metadata['dir'] = 1;
    $metadata['filesize'] = 0;
    $metadata['timestamp'] = time();
    $metadata['uid'] = 'S3 File System';
    // The posix S_IFDIR flag.
    $metadata['mode'] = 0040000;
  }
  else {
    // The caller sent us some actual metadata, so this must be a file.
    if (isset($s3_metadata['Size'])) {
      $metadata['filesize'] = $s3_metadata['Size'];
    }
    if (isset($s3_metadata['LastModified'])) {
      $metadata['timestamp'] = date('U', strtotime($s3_metadata['LastModified']));
    }
    if (isset($s3_metadata['Owner']['ID'])) {
      $metadata['uid'] = $s3_metadata['Owner']['ID'];
    }
    $metadata['dir'] = 0;
    // The S_IFREG posix flag.
    $metadata['mode'] = 0100000;
  }
  // Everything is writeable.
  $metadata['mode'] |= 0777;
  return $metadata;
}

/**
 * Sets up the S3Client object.
 *
 * For performance reasons, only one S3Client object will ever be created
 * within a single request.
 *
 * @return Aws\S3\S3Client
 *   The fully-configured S3Client object.
 */
function _s3fs_get_amazons3_client($config) {
  static $s3;
  
  if (!isset($s3)) {
    $secret_key = variable_get('awssdk2_secret_key', FALSE);
    $access_key = variable_get('awssdk2_access_key', FALSE);
    $library = libraries_load('awssdk2');
    if (!$library['loaded']) {
      throw new s3fsException(t('Unable to load the AWS SDK. Please ensure that the awssdk2 library is installed correctly.'));
    }
    elseif (!class_exists('Aws\S3\S3Client')) {
      throw new s3fsException(t('Cannot load Aws\S3\S3Client class. Please ensure that the awssdk2 library is installed correctly.'));
    }
    elseif (!$secret_key || !$access_key) {
      throw new s3fsException(t("Your AWS credentials have not been properly configured.
        Please set \$conf['awssdk2_access_key'] and \$conf['awssdk2_secret_key'] in your site's settings.php file."));
    }
    
    // Create and configure the S3Client object.
    $s3 = Aws\S3\S3Client::factory(array(
      'key'    => $access_key,
      'secret' => $secret_key,
    ));
    if (!empty($config['region'])) {
      $s3->setRegion($config['region']);
    }
    if (!empty($config['use_customhost'])) {
      $s3->setBaseURL($config['hostname']);
    }
  }
  
  return $s3;
}

/**
 * Returns the current set of configuration settings as an associative array.
 *
 * The functions in S3 File System which utilize variables always accept a
 * config array instead of calling variable_get() themselves. This allows for
 * their callers to override these configuration settings when necessary (like
 * when attempting to validate new settings).
 *
 * @return array
 */
function _s3fs_get_config() {
  $config = array();
  $variable_names = db_select('variable', 'v')
    ->fields('v', array('name'))
    ->condition('name', 's3fs_%', 'LIKE')
    ->execute()
    ->fetchCol(0);
  foreach ($variable_names as $name) {
    $shortname = str_replace('s3fs_', '', $name);
    $config[$shortname] = variable_get($name, '');
  }
  return $config;
}
